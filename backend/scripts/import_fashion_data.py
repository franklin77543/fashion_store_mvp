"""
åŒ¯å…¥ Fashion Dataset åˆ°è³‡æ–™åº«
- è®€å– styles.csv å’Œ styles/*.json
- è³‡æ–™æ¸…ç†èˆ‡è½‰æ›
- æ‰¹æ¬¡åŒ¯å…¥åˆ° SQLite è³‡æ–™åº«
"""
import sys
import json
import pandas as pd
from pathlib import Path
from typing import Dict, List, Optional, Set
from datetime import datetime

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.db.session import SessionLocal
from app.models import (
    Gender, MasterCategory, SubCategory, ArticleType,
    Colour, Season, Usage, Brand, Product, ProductImage,
    ProductAttribute, ProductSize
)


class FashionDataImporter:
    """Fashion Dataset åŒ¯å…¥å™¨"""
    
    def __init__(self, dataset_path: str = "../fashion-dataset"):
        self.dataset_path = Path(dataset_path)
        self.csv_path = self.dataset_path / "styles.csv"
        self.json_dir = self.dataset_path / "styles"
        self.images_dir = self.dataset_path / "images"
        
        self.db = SessionLocal()
        
        # å¿«å–æŸ¥æ‰¾è¡¨ ID (é¿å…é‡è¤‡æŸ¥è©¢)
        self.gender_cache: Dict[str, int] = {}
        self.master_category_cache: Dict[str, int] = {}
        self.sub_category_cache: Dict[str, int] = {}
        self.article_type_cache: Dict[str, int] = {}
        self.colour_cache: Dict[str, int] = {}
        self.season_cache: Dict[str, int] = {}
        self.usage_cache: Dict[str, int] = {}
        self.brand_cache: Dict[str, int] = {}
        
        # çµ±è¨ˆè³‡æ–™
        self.stats = {
            "total_rows": 0,
            "successful_imports": 0,
            "failed_imports": 0,
            "skipped_rows": 0,
            "lookup_tables": {},
            "errors": []
        }
    
    def import_all(self):
        """åŸ·è¡Œå®Œæ•´åŒ¯å…¥æµç¨‹"""
        print("=" * 80)
        print("ğŸš€ é–‹å§‹åŒ¯å…¥ Fashion Dataset")
        print("=" * 80)
        
        try:
            # 1. åŒ¯å…¥æŸ¥æ‰¾è¡¨
            self.import_lookup_tables()
            
            # 2. è®€å– CSV
            print("\n" + "=" * 80)
            print("ğŸ“– è®€å– CSV æª”æ¡ˆ...")
            df = pd.read_csv(self.csv_path, on_bad_lines='skip', encoding='utf-8')
            self.stats["total_rows"] = len(df)
            print(f"âœ… è®€å– {len(df)} ç­†è³‡æ–™")
            
            # 3. æ‰¹æ¬¡åŒ¯å…¥å•†å“
            self.import_products(df)
            
            # 4. é¡¯ç¤ºçµ±è¨ˆ
            self.print_statistics()
            
            print("\n" + "=" * 80)
            print("ğŸ‰ è³‡æ–™åŒ¯å…¥å®Œæˆï¼")
            print("=" * 80)
            
        except Exception as e:
            print(f"\nâŒ åŒ¯å…¥å¤±æ•—: {e}")
            self.db.rollback()
            raise
        finally:
            self.db.close()
    
    def import_lookup_tables(self):
        """åŒ¯å…¥æ‰€æœ‰æŸ¥æ‰¾è¡¨"""
        print("\n" + "=" * 80)
        print("ğŸ“Š åŒ¯å…¥æŸ¥æ‰¾è¡¨...")
        print("=" * 80)
        
        # è®€å– CSV ä»¥å–å¾—æ‰€æœ‰å”¯ä¸€å€¼ (è™•ç†æ ¼å¼éŒ¯èª¤)
        df = pd.read_csv(self.csv_path, on_bad_lines='skip', encoding='utf-8')
        
        # 1. Genders
        self._import_genders(df)
        
        # 2. Categories
        self._import_master_categories(df)
        
        # 3. Sub Categories
        self._import_sub_categories(df)
        
        # 4. Article Types
        self._import_article_types(df)
        
        # 5. Colours
        self._import_colours(df)
        
        # 6. Seasons
        self._import_seasons(df)
        
        # 7. Usages
        self._import_usages(df)
        
        # 8. Brands
        self._import_brands(df)
        
        print("\nâœ… æ‰€æœ‰æŸ¥æ‰¾è¡¨åŒ¯å…¥å®Œæˆ")
    
    def _import_master_categories(self, df: pd.DataFrame):
        """
        åŒ¯å…¥ä¸»åˆ†é¡
        """
        print("\nğŸ“ åŒ¯å…¥ä¸»åˆ†é¡ (MasterCategories)...")

        unique_master_categories = df['masterCategory'].dropna().unique()
        created = 0

        for cat_name in unique_master_categories:
            existing = self.db.query(MasterCategory).filter_by(name=cat_name).first()
            if not existing:
                master_category = MasterCategory(
                    name=cat_name,
                    display_name=self._translate_category(cat_name)
                )
                self.db.add(master_category)
                created += 1

        self.db.commit()

        # å»ºç«‹å¿«å–
        for cat in self.db.query(MasterCategory).all():
            self.master_category_cache[cat.name] = cat.id

        total = len(self.master_category_cache)
        print(f"âœ… ä¸»åˆ†é¡: {total} å€‹ (æ–°å¢ {created} å€‹)")
        self.stats["lookup_tables"]["master_categories"] = total
    
    def _import_sub_categories(self, df: pd.DataFrame):
        """åŒ¯å…¥å­åˆ†é¡"""
        print("\nğŸ“ åŒ¯å…¥å­åˆ†é¡ (Sub Categories)...")
        
        # éœ€è¦åŒæ™‚è€ƒæ…® category å’Œ subCategory çš„çµ„åˆ
        unique_pairs = df[['masterCategory', 'subCategory']].dropna().drop_duplicates()
        created = 0
        
        for _, row in unique_pairs.iterrows():
            master_cat_name = row['masterCategory']
            sub_cat_name = row['subCategory']

            if master_cat_name not in self.master_category_cache:
                continue

            existing = self.db.query(SubCategory).filter_by(name=sub_cat_name).first()
            if not existing:
                sub_cat = SubCategory(
                    master_category_id=self.master_category_cache[master_cat_name],
                    name=sub_cat_name,
                    display_name=self._translate_sub_category(sub_cat_name)
                )
                self.db.add(sub_cat)
                created += 1
        
        self.db.commit()
        
        # å»ºç«‹å¿«å–
        for sub_cat in self.db.query(SubCategory).all():
            self.sub_category_cache[sub_cat.name] = sub_cat.id
        
        total = len(self.sub_category_cache)
        print(f"âœ… å­åˆ†é¡: {total} å€‹ (æ–°å¢ {created} å€‹)")
        self.stats["lookup_tables"]["sub_categories"] = total
    
    def _import_article_types(self, df: pd.DataFrame):
        """åŒ¯å…¥å•†å“é¡å‹"""
        print("\nğŸ“ åŒ¯å…¥å•†å“é¡å‹ (Article Types)...")
        
        unique_types = df['articleType'].dropna().unique()
        created = 0
        
        for type_name in unique_types:
            existing = self.db.query(ArticleType).filter_by(name=type_name).first()
            if not existing:
                article_type = ArticleType(
                    name=type_name,
                    display_name=type_name  # ä¿æŒåŸå
                )
                self.db.add(article_type)
                created += 1
        
        self.db.commit()
        
        # å»ºç«‹å¿«å–
        for at in self.db.query(ArticleType).all():
            self.article_type_cache[at.name] = at.id
        
        total = len(self.article_type_cache)
        print(f"âœ… å•†å“é¡å‹: {total} å€‹ (æ–°å¢ {created} å€‹)")
        self.stats["lookup_tables"]["article_types"] = total
    
    def _import_colours(self, df: pd.DataFrame):
        """åŒ¯å…¥é¡è‰²"""
        print("\nğŸ“ åŒ¯å…¥é¡è‰² (Colours)...")
        
        unique_colours = df['baseColour'].dropna().unique()
        created = 0
        
        for colour_name in unique_colours:
            # æ¨™æº–åŒ–é¡è‰²åç¨± (è™•ç†å¤§å°å¯«ã€ç©ºæ ¼)
            colour_name_clean = colour_name.strip()
            
            existing = self.db.query(Colour).filter_by(name=colour_name_clean).first()
            if not existing:
                colour = Colour(
                    name=colour_name_clean,
                    display_name=self._translate_colour(colour_name_clean),
                    hex_code=self._get_colour_hex(colour_name_clean)
                )
                self.db.add(colour)
                created += 1
        
        self.db.commit()
        
        # å»ºç«‹å¿«å–
        for colour in self.db.query(Colour).all():
            self.colour_cache[colour.name] = colour.id
        
        total = len(self.colour_cache)
        print(f"âœ… é¡è‰²: {total} å€‹ (æ–°å¢ {created} å€‹)")
        self.stats["lookup_tables"]["colours"] = total
    
    def _import_seasons(self, df: pd.DataFrame):
        """åŒ¯å…¥å­£ç¯€"""
        print("\nğŸ“ åŒ¯å…¥å­£ç¯€ (Seasons)...")
        
        unique_seasons = df['season'].dropna().unique()
        created = 0
        
        for season_name in unique_seasons:
            existing = self.db.query(Season).filter_by(name=season_name).first()
            if not existing:
                season = Season(
                    name=season_name,
                    display_name=self._translate_season(season_name)
                )
                self.db.add(season)
                created += 1
        
        self.db.commit()
        
        # å»ºç«‹å¿«å–
        for season in self.db.query(Season).all():
            self.season_cache[season.name] = season.id
        
        total = len(self.season_cache)
        print(f"âœ… å­£ç¯€: {total} å€‹ (æ–°å¢ {created} å€‹)")
        self.stats["lookup_tables"]["seasons"] = total
    
    def _import_usages(self, df: pd.DataFrame):
        """åŒ¯å…¥ä½¿ç”¨å ´åˆ"""
        print("\nğŸ“ åŒ¯å…¥ä½¿ç”¨å ´åˆ (Usages)...")
        
        unique_usages = df['usage'].dropna().unique()
        created = 0
        
        for usage_name in unique_usages:
            existing = self.db.query(Usage).filter_by(name=usage_name).first()
            if not existing:
                usage = Usage(
                    name=usage_name,
                    display_name=self._translate_usage(usage_name)
                )
                self.db.add(usage)
                created += 1
        
        self.db.commit()
        
        # å»ºç«‹å¿«å–
        for usage in self.db.query(Usage).all():
            self.usage_cache[usage.name] = usage.id
        
        total = len(self.usage_cache)
        print(f"âœ… ä½¿ç”¨å ´åˆ: {total} å€‹ (æ–°å¢ {created} å€‹)")
        self.stats["lookup_tables"]["usages"] = total
    
    def _import_brands(self, df: pd.DataFrame):
        """åŒ¯å…¥å“ç‰Œ (å¾ JSON è®€å–)"""
        print("\nğŸ“ åŒ¯å…¥å“ç‰Œ (Brands)...")
        
        brands_set: Set[str] = set()
        
        # å¾ JSON æª”æ¡ˆè®€å–å“ç‰Œ
        json_files = list(self.json_dir.glob("*.json"))
        for json_file in json_files[:1000]:  # å…ˆè®€å– 1000 å€‹æª”æ¡ˆä»¥å»ºç«‹å“ç‰Œåˆ—è¡¨
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if 'data' in data and 'brandName' in data['data']:
                        brand_name = data['data']['brandName']
                        if brand_name and brand_name.strip():
                            brands_set.add(brand_name.strip())
            except Exception:
                continue
        
        created = 0
        for brand_name in brands_set:
            existing = self.db.query(Brand).filter_by(name=brand_name).first()
            if not existing:
                brand = Brand(
                    name=brand_name,
                    display_name=brand_name,
                    is_active=True
                )
                self.db.add(brand)
                created += 1
        
        self.db.commit()
        
        # å»ºç«‹å¿«å–
        for brand in self.db.query(Brand).all():
            self.brand_cache[brand.name] = brand.id
        
        total = len(self.brand_cache)
        print(f"âœ… å“ç‰Œ: {total} å€‹ (æ–°å¢ {created} å€‹)")
        self.stats["lookup_tables"]["brands"] = total
    
    def import_products(self, df: pd.DataFrame):
        """æ‰¹æ¬¡åŒ¯å…¥å•†å“"""
        print("\n" + "=" * 80)
        print("ğŸ“¦ åŒ¯å…¥å•†å“è³‡æ–™...")
        print("=" * 80)
        
        batch_size = 100
        total_rows = len(df)
        
        for batch_start in range(0, total_rows, batch_size):
            batch_end = min(batch_start + batch_size, total_rows)
            batch_df = df.iloc[batch_start:batch_end]
            
            for idx, row in batch_df.iterrows():
                try:
                    self._import_single_product(row)
                    self.stats["successful_imports"] += 1
                except Exception as e:
                    self.stats["failed_imports"] += 1
                    self.stats["errors"].append({
                        "row": idx,
                        "product_id": row.get('id'),
                        "error": str(e)
                    })
                    # Rollback ç•¶å‰éŒ¯èª¤ï¼Œç¹¼çºŒè™•ç†ä¸‹ä¸€ç­†
                    self.db.rollback()
            
            # æ‰¹æ¬¡æäº¤
            try:
                self.db.commit()
            except Exception as e:
                print(f"âš ï¸ æ‰¹æ¬¡æäº¤å¤±æ•—: {e}")
                self.db.rollback()
            
            # é€²åº¦é¡¯ç¤º
            progress = (batch_end / total_rows) * 100
            print(f"é€²åº¦: {batch_end}/{total_rows} ({progress:.1f}%) - "
                  f"æˆåŠŸ: {self.stats['successful_imports']}, "
                  f"å¤±æ•—: {self.stats['failed_imports']}")
        
        print(f"\nâœ… å•†å“åŒ¯å…¥å®Œæˆ: {self.stats['successful_imports']} ç­†æˆåŠŸ")
    
    def _import_single_product(self, row: pd.Series):
        """åŒ¯å…¥å–®ä¸€å•†å“"""
        product_id = int(row['id'])
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = self.db.query(Product).filter_by(id=product_id).first()
        if existing:
            self.stats["skipped_rows"] += 1
            return
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½
        product_name = row.get('productDisplayName')
        if pd.isna(product_name) or not str(product_name).strip():
            # è·³éæ²’æœ‰å•†å“åç¨±çš„è³‡æ–™
            self.stats["skipped_rows"] += 1
            return
        
        # è®€å– JSON è³‡æ–™
        json_data = self._read_product_json(product_id)
        
        # å»ºç«‹å•†å“
        product = Product(
            id=product_id,
            product_display_name=str(product_name).strip(),
            gender_id=self._get_gender_id(row.get('gender')),
            master_category_id=self._get_master_category_id(row.get('masterCategory')),
            sub_category_id=self._get_sub_category_id(row.get('subCategory')),
            article_type_id=self._get_article_type_id(row.get('articleType')),
            base_colour_id=self._get_colour_id(row.get('baseColour')),
            season_id=self._get_season_id(row.get('season')),
            usage_id=self._get_usage_id(row.get('usage')),
            year=self._parse_year(row.get('year')),
            brand_id=self._get_brand_id_from_json(json_data),
            price=self._parse_price(json_data),
            description=self._get_description(json_data),
            is_active=True,
            stock_count=100  # é è¨­åº«å­˜
        )
        
        self.db.add(product)
        self.db.flush()  # å–å¾— product.id
        
        # åŒ¯å…¥åœ–ç‰‡
        self._import_product_images(product, json_data)
        
        # åŒ¯å…¥å±¬æ€§
        self._import_product_attributes(product, json_data)
    
    def _import_product_images(self, product: Product, json_data: Optional[Dict]):
        """åŒ¯å…¥å•†å“åœ–ç‰‡"""
        if not json_data or 'data' not in json_data:
            return
        
        data = json_data['data']
        display_order = 0
        
        # ä¸»åœ–
        if 'styleImages' in data:
            style_images = data['styleImages']
            
            # Default (æ­£é¢åœ–)
            if 'default' in style_images:
                image_url = style_images['default'].get('imageURL', '')
                if image_url:
                    product_image = ProductImage(
                        product_id=product.id,
                        image_type='front',
                        image_url=image_url,
                        is_primary=True,
                        display_order=display_order
                    )
                    self.db.add(product_image)
                    display_order += 1
                    product.has_front_image = True
            
            # Back
            if 'back' in style_images:
                image_url = style_images['back'].get('imageURL', '')
                if image_url:
                    product_image = ProductImage(
                        product_id=product.id,
                        image_type='back',
                        image_url=image_url,
                        is_primary=False,
                        display_order=display_order
                    )
                    self.db.add(product_image)
                    display_order += 1
                    product.has_back_image = True
            
            # Search
            if 'search' in style_images:
                image_url = style_images['search'].get('imageURL', '')
                if image_url:
                    product_image = ProductImage(
                        product_id=product.id,
                        image_type='search',
                        image_url=image_url,
                        is_primary=False,
                        display_order=display_order
                    )
                    self.db.add(product_image)
                    product.has_search_image = True
    
    def _import_product_attributes(self, product: Product, json_data: Optional[Dict]):
        """åŒ¯å…¥å•†å“å±¬æ€§"""
        if not json_data or 'data' not in json_data:
            return
        
        data = json_data['data']
        
        # å¾ JSON æå–å„ç¨®å±¬æ€§
        attributes = {}
        
        if 'productDescriptors' in data:
            descriptors = data['productDescriptors'].get('description', {})
            for key, value in descriptors.items():
                if value:
                    attributes[key] = str(value)
        
        # å„²å­˜å±¬æ€§
        for key, value in attributes.items():
            product_attr = ProductAttribute(
                product_id=product.id,
                attribute_key=key,
                attribute_value=value
            )
            self.db.add(product_attr)

    def _import_genders(self, df: pd.DataFrame):
        """åŒ¯å…¥æ€§åˆ¥æŸ¥æ‰¾è¡¨"""
        print("\nğŸ“ åŒ¯å…¥æ€§åˆ¥ (Genders)...")
        unique_genders = df['gender'].dropna().unique()
        created = 0
        for gender_name in unique_genders:
            existing = self.db.query(Gender).filter_by(name=gender_name).first()
            if not existing:
                gender = Gender(
                    name=gender_name,
                    display_name=self._translate_gender(gender_name)
                )
                self.db.add(gender)
                created += 1
        self.db.commit()
        # å»ºç«‹å¿«å–
        for gender in self.db.query(Gender).all():
            self.gender_cache[gender.name] = gender.id
        total = len(self.gender_cache)
        print(f"âœ… æ€§åˆ¥: {total} å€‹ (æ–°å¢ {created} å€‹)")
        self.stats["lookup_tables"]["genders"] = total

    def _read_product_json(self, product_id: int) -> Optional[Dict]:
        """è®€å–å•†å“ JSON æª”æ¡ˆ"""
        json_file = self.json_dir / f"{product_id}.json"
        if not json_file.exists():
            return None
        
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return None
    
    # ===== è¼”åŠ©æ–¹æ³• =====
    
    def _get_gender_id(self, gender_name) -> Optional[int]:
        if pd.isna(gender_name):
            return None
        return self.gender_cache.get(gender_name)
    
    def _get_master_category_id(self, master_category_name) -> Optional[int]:
        if pd.isna(master_category_name):
            return None
        return self.master_category_cache.get(master_category_name)
    
    def _get_sub_category_id(self, sub_category_name) -> Optional[int]:
        if pd.isna(sub_category_name):
            return None
        return self.sub_category_cache.get(sub_category_name)
    
    def _get_article_type_id(self, article_type_name) -> Optional[int]:
        if pd.isna(article_type_name):
            return None
        return self.article_type_cache.get(article_type_name)
    
    def _get_colour_id(self, colour_name) -> Optional[int]:
        if pd.isna(colour_name):
            return None
        colour_name_clean = str(colour_name).strip()
        return self.colour_cache.get(colour_name_clean)
    
    def _get_season_id(self, season_name) -> Optional[int]:
        if pd.isna(season_name):
            return None
        return self.season_cache.get(season_name)
    
    def _get_usage_id(self, usage_name) -> Optional[int]:
        if pd.isna(usage_name):
            return None
        return self.usage_cache.get(usage_name)
    
    def _get_brand_id_from_json(self, json_data: Optional[Dict]) -> Optional[int]:
        if not json_data or 'data' not in json_data:
            return None
        
        brand_name = json_data['data'].get('brandName')
        if not brand_name:
            return None
        
        return self.brand_cache.get(brand_name.strip())
    
    def _parse_year(self, year_value) -> Optional[int]:
        if pd.isna(year_value):
            return None
        try:
            return int(year_value)
        except (ValueError, TypeError):
            return None
    
    def _parse_price(self, json_data: Optional[Dict]) -> float:
        """å¾ JSON è§£æåƒ¹æ ¼"""
        if not json_data or 'data' not in json_data:
            return 0.0
        
        price_str = json_data['data'].get('price', '0')
        if not price_str:
            return 0.0
        
        # ç§»é™¤è²¨å¹£ç¬¦è™Ÿå’Œé€—è™Ÿ
        price_str = str(price_str).replace('â‚¹', '').replace(',', '').strip()
        
        try:
            return float(price_str)
        except (ValueError, TypeError):
            return 0.0
    
    def _get_description(self, json_data: Optional[Dict]) -> Optional[str]:
        """å¾ JSON å–å¾—å•†å“æè¿°"""
        if not json_data or 'data' not in json_data:
            return None
        
        return json_data['data'].get('productDisplayName')
    
    # ===== ç¿»è­¯æ–¹æ³• =====
    
    def _translate_gender(self, name: str) -> str:
        translations = {
            'Men': 'ç”·æ€§',
            'Women': 'å¥³æ€§',
            'Boys': 'ç”·ç«¥',
            'Girls': 'å¥³ç«¥',
            'Unisex': 'ä¸­æ€§'
        }
        return translations.get(name, name)
    
    def _translate_category(self, name: str) -> str:
        translations = {
            'Apparel': 'æœé£¾',
            'Accessories': 'é…ä»¶',
            'Footwear': 'é‹é¡',
            'Personal Care': 'å€‹äººè­·ç†',
            'Free Items': 'å…è²»å•†å“',
            'Sporting Goods': 'é‹å‹•ç”¨å“',
            'Home': 'å±…å®¶ç”¨å“'
        }
        return translations.get(name, name)
    
    def _translate_sub_category(self, name: str) -> str:
        translations = {
            'Topwear': 'ä¸Šè¡£',
            'Bottomwear': 'ä¸‹è‘—',
            'Shoes': 'é‹å­',
            'Watches': 'æ‰‹éŒ¶',
            'Socks': 'è¥ªå­',
            'Bags': 'åŒ…åŒ…',
            'Belts': 'çš®å¸¶',
            'Flip Flops': 'æ‹–é‹',
            'Innerwear': 'å…§è¡£',
            'Sandal': 'æ¶¼é‹',
            'Shoe Accessories': 'é‹é¡é…ä»¶',
            'Fragrance': 'é¦™æ°´',
            'Jewellery': 'ç å¯¶',
            'Eyewear': 'çœ¼é¡',
            'Dress': 'æ´‹è£',
            'Loungewear and Nightwear': 'å±…å®¶ç¡è¡£',
            'Wallets': 'éŒ¢åŒ…',
            'Apparel Set': 'å¥—è£',
            'Headwear': 'å¸½å­',
            'Mufflers': 'åœå·¾',
            'Skin Care': 'è­·è†šå“',
            'Makeup': 'åŒ–å¦å“',
            'Free Gifts': 'è´ˆå“',
            'Ties': 'é ˜å¸¶',
            'Skin': 'çš®è†šä¿é¤Š',
            'Beauty Accessories': 'ç¾å¦é…ä»¶',
            'Water Bottle': 'æ°´å£º',
            'Sports Accessories': 'é‹å‹•é…ä»¶',
            'Stoles': 'æŠ«è‚©',
            'Scarves': 'åœå·¾',
            'Sports Equipment': 'é‹å‹•å™¨æ',
            'Cufflinks': 'è¢–æ‰£',
            'Hair Accessory': 'é«®é£¾',
            'Gloves': 'æ‰‹å¥—',
            'Umbrellas': 'é›¨å‚˜',
            'Vouchers': 'ç¦®åˆ¸',
            'Lips': 'å”‡éƒ¨ä¿é¤Š',
            'Saree': 'ç´—éº—',
            'Perfumes': 'é¦™æ°´'
        }
        return translations.get(name, name)
    
    def _translate_colour(self, name: str) -> str:
        translations = {
            'Black': 'é»‘è‰²',
            'White': 'ç™½è‰²',
            'Blue': 'è—è‰²',
            'Red': 'ç´…è‰²',
            'Grey': 'ç°è‰²',
            'Navy Blue': 'æµ·è»è—',
            'Green': 'ç¶ è‰²',
            'Purple': 'ç´«è‰²',
            'Pink': 'ç²‰ç´…è‰²',
            'Yellow': 'é»ƒè‰²',
            'Orange': 'æ©™è‰²',
            'Brown': 'æ£•è‰²',
            'Beige': 'ç±³è‰²',
            'Olive': 'æ©„æ¬–ç¶ ',
            'Maroon': 'æ —è‰²',
            'Silver': 'éŠ€è‰²',
            'Gold': 'é‡‘è‰²',
            'Cream': 'å¥¶æ²¹è‰²',
            'Tan': 'è¤è‰²',
            'Khaki': 'å¡å…¶è‰²',
            'Turquoise Blue': 'åœŸè€³å…¶è—',
            'Charcoal': 'ç‚­ç°è‰²',
            'Coffee Brown': 'å’–å•¡æ£•',
            'Mushroom Brown': 'è˜‘è‡æ£•',
            'Burgundy': 'å‹ƒæ ¹åœ°ç´…',
            'Lavender': 'è–°è¡£è‰ç´«',
            'Mint': 'è–„è·ç¶ ',
            'Peach': 'æ¡ƒè‰²',
            'Coral': 'çŠç‘šè‰²',
            'Rust': 'éµé½è‰²',
            'Teal': 'æ°´é´¨è‰²',
            'Multi': 'å¤šè‰²',
            'Metallic': 'é‡‘å±¬è‰²',
            'Fluorescent Green': 'è¢å…‰ç¶ '
        }
        return translations.get(name, name)
    
    def _translate_season(self, name: str) -> str:
        translations = {
            'Summer': 'å¤å­£',
            'Winter': 'å†¬å­£',
            'Spring': 'æ˜¥å­£',
            'Fall': 'ç§‹å­£'
        }
        return translations.get(name, name)
    
    def _translate_usage(self, name: str) -> str:
        translations = {
            'Casual': 'ä¼‘é–’',
            'Formal': 'æ­£å¼',
            'Sports': 'é‹å‹•',
            'Ethnic': 'æ°‘æ—é¢¨',
            'Party': 'æ´¾å°',
            'Smart Casual': 'æ™ºèƒ½ä¼‘é–’',
            'Travel': 'æ—…è¡Œ',
            'Home': 'å±…å®¶'
        }
        return translations.get(name, name)
    
    def _get_colour_hex(self, name: str) -> Optional[str]:
        """å–å¾—é¡è‰²çš„ HEX ä»£ç¢¼"""
        colour_hex = {
            'Black': '#000000',
            'White': '#FFFFFF',
            'Blue': '#0000FF',
            'Red': '#FF0000',
            'Grey': '#808080',
            'Navy Blue': '#000080',
            'Green': '#008000',
            'Purple': '#800080',
            'Pink': '#FFC0CB',
            'Yellow': '#FFFF00',
            'Orange': '#FFA500',
            'Brown': '#A52A2A',
            'Beige': '#F5F5DC',
            'Olive': '#808000',
            'Maroon': '#800000',
            'Silver': '#C0C0C0',
            'Gold': '#FFD700',
            'Cream': '#FFFDD0',
            'Tan': '#D2B48C',
            'Khaki': '#F0E68C',
            'Turquoise Blue': '#40E0D0',
            'Charcoal': '#36454F',
            'Coffee Brown': '#6F4E37',
            'Burgundy': '#800020',
            'Lavender': '#E6E6FA',
            'Mint': '#98FF98',
            'Peach': '#FFE5B4',
            'Coral': '#FF7F50',
            'Teal': '#008080'
        }
        return colour_hex.get(name)
    
    def print_statistics(self):
        """é¡¯ç¤ºåŒ¯å…¥çµ±è¨ˆ"""
        print("\n" + "=" * 80)
        print("ğŸ“Š åŒ¯å…¥çµ±è¨ˆ")
        print("=" * 80)
        
        print(f"\næŸ¥æ‰¾è¡¨:")
        for table_name, count in self.stats["lookup_tables"].items():
            print(f"  - {table_name}: {count} ç­†")
        
        print(f"\nå•†å“:")
        print(f"  - ç¸½ç­†æ•¸: {self.stats['total_rows']}")
        print(f"  - æˆåŠŸåŒ¯å…¥: {self.stats['successful_imports']}")
        print(f"  - å¤±æ•—: {self.stats['failed_imports']}")
        print(f"  - è·³é (å·²å­˜åœ¨): {self.stats['skipped_rows']}")
        
        if self.stats["errors"]:
            print(f"\nâŒ éŒ¯èª¤è¨˜éŒ„ (å‰ 10 ç­†):")
            for error in self.stats["errors"][:10]:
                print(f"  - è¡Œ {error['row']} (ID: {error['product_id']}): {error['error']}")


def main():
    """ä¸»ç¨‹å¼"""
    import argparse
    
    parser = argparse.ArgumentParser(description='åŒ¯å…¥ Fashion Dataset')
    parser.add_argument('--dataset-path', default='../fashion-dataset',
                        help='Dataset è·¯å¾‘')
    
    args = parser.parse_args()
    
    importer = FashionDataImporter(args.dataset_path)
    importer.import_all()


if __name__ == "__main__":
    main()
