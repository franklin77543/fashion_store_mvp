"""
åˆ†æ Fashion Dataset çš„è³‡æ–™çµæ§‹
- åˆ†æ styles.csv çš„æ¬„ä½å’Œè³‡æ–™åˆ†å¸ƒ
- åˆ†æ styles/*.json çš„è©³ç´°è³‡è¨Š
- çµ±è¨ˆè³‡æ–™å®Œæ•´æ€§
"""

import pandas as pd
import json
import os
from pathlib import Path
from collections import Counter

# è¨­å®šè³‡æ–™è·¯å¾‘
BASE_DIR = Path(__file__).parent.parent.parent
DATASET_DIR = BASE_DIR / "fashion-dataset"
CSV_FILE = DATASET_DIR / "styles.csv"
JSON_DIR = DATASET_DIR / "styles"
IMAGES_DIR = DATASET_DIR / "images"

def analyze_csv():
    """åˆ†æ styles.csv æª”æ¡ˆ"""
    print("=" * 80)
    print("ğŸ“Š åˆ†æ styles.csv")
    print("=" * 80)
    
    # è®€å– CSV
    df = pd.read_csv(CSV_FILE, on_bad_lines='skip')
    
    print(f"\nâœ… æˆåŠŸè®€å– CSV æª”æ¡ˆ")
    print(f"ğŸ“¦ ç¸½å•†å“æ•¸é‡: {len(df):,}")
    
    # é¡¯ç¤ºæ¬„ä½è³‡è¨Š
    print(f"\nğŸ“‹ æ¬„ä½åˆ—è¡¨ ({len(df.columns)} å€‹æ¬„ä½):")
    print("-" * 80)
    for i, col in enumerate(df.columns, 1):
        dtype = df[col].dtype
        null_count = df[col].isnull().sum()
        null_pct = (null_count / len(df)) * 100
        print(f"{i:2d}. {col:25s} | å‹æ…‹: {str(dtype):10s} | ç¼ºå¤±: {null_count:6,} ({null_pct:5.2f}%)")
    
    # é¡¯ç¤ºå‰ 5 ç­†è³‡æ–™
    print(f"\nğŸ“„ å‰ 5 ç­†è³‡æ–™:")
    print("-" * 80)
    print(df.head())
    
    # çµ±è¨ˆå„æ¬„ä½çš„åˆ†å¸ƒ
    print(f"\nğŸ“Š è³‡æ–™åˆ†å¸ƒçµ±è¨ˆ:")
    print("-" * 80)
    
    categorical_cols = ['gender', 'masterCategory', 'subCategory', 'articleType', 
                       'baseColour', 'season', 'usage']
    
    for col in categorical_cols:
        if col in df.columns:
            print(f"\nâ–¶ {col}:")
            value_counts = df[col].value_counts()
            for val, count in value_counts.head(10).items():
                pct = (count / len(df)) * 100
                print(f"  - {str(val):30s}: {count:6,} ({pct:5.2f}%)")
            if len(value_counts) > 10:
                print(f"  ... é‚„æœ‰ {len(value_counts) - 10} å€‹å…¶ä»–å€¼")
    
    # å¹´ä»½çµ±è¨ˆ
    if 'year' in df.columns:
        print(f"\nâ–¶ year:")
        year_counts = df['year'].value_counts().sort_index()
        for year, count in year_counts.items():
            if pd.notna(year):
                pct = (count / len(df)) * 100
                print(f"  - {int(year)}: {count:6,} ({pct:5.2f}%)")
    
    return df

def analyze_json_files(df, sample_size=10):
    """åˆ†æ styles/*.json æª”æ¡ˆ"""
    print("\n" + "=" * 80)
    print("ğŸ“Š åˆ†æ styles/*.json æª”æ¡ˆ")
    print("=" * 80)
    
    if not JSON_DIR.exists():
        print(f"âŒ æ‰¾ä¸åˆ° JSON ç›®éŒ„: {JSON_DIR}")
        return
    
    json_files = list(JSON_DIR.glob("*.json"))
    print(f"\nğŸ“¦ JSON æª”æ¡ˆæ•¸é‡: {len(json_files):,}")
    
    if len(json_files) == 0:
        print("âš ï¸  æ²’æœ‰æ‰¾åˆ° JSON æª”æ¡ˆ")
        return
    
    # æ”¶é›†æ‰€æœ‰æ¬„ä½
    all_fields = set()
    sample_data = []
    
    print(f"\nğŸ” åˆ†æå‰ {sample_size} å€‹ JSON æª”æ¡ˆ...")
    
    for i, json_file in enumerate(json_files[:sample_size]):
        with open(json_file, 'r', encoding='utf-8') as f:
            try:
                data = json.load(f)
                all_fields.update(data.keys())
                sample_data.append(data)
            except json.JSONDecodeError:
                print(f"âš ï¸  ç„¡æ³•è§£æ: {json_file.name}")
    
    print(f"\nğŸ“‹ JSON æª”æ¡ˆåŒ…å«çš„æ¬„ä½ ({len(all_fields)} å€‹):")
    print("-" * 80)
    for field in sorted(all_fields):
        print(f"  - {field}")
    
    # é¡¯ç¤ºç¯„ä¾‹è³‡æ–™
    if sample_data:
        print(f"\nğŸ“„ ç¬¬ä¸€å€‹ JSON æª”æ¡ˆçš„å®Œæ•´å…§å®¹:")
        print("-" * 80)
        print(json.dumps(sample_data[0], indent=2, ensure_ascii=False))
        
        # åˆ†æåƒ¹æ ¼è³‡è¨Š
        prices = [d.get('price') for d in sample_data if d.get('price')]
        if prices:
            print(f"\nğŸ’° åƒ¹æ ¼è³‡è¨Šç¯„ä¾‹:")
            for i, price in enumerate(prices[:5], 1):
                print(f"  {i}. {price}")

def check_images(df):
    """æª¢æŸ¥åœ–ç‰‡æª”æ¡ˆå­˜åœ¨æ€§"""
    print("\n" + "=" * 80)
    print("ğŸ–¼ï¸  æª¢æŸ¥åœ–ç‰‡æª”æ¡ˆ")
    print("=" * 80)
    
    if not IMAGES_DIR.exists():
        print(f"âŒ æ‰¾ä¸åˆ°åœ–ç‰‡ç›®éŒ„: {IMAGES_DIR}")
        return
    
    # çµ±è¨ˆåœ–ç‰‡æ•¸é‡
    image_files = list(IMAGES_DIR.glob("*.jpg"))
    print(f"\nğŸ“¦ åœ–ç‰‡æª”æ¡ˆæ•¸é‡: {len(image_files):,}")
    
    # æª¢æŸ¥å‰ 100 å€‹å•†å“çš„åœ–ç‰‡æ˜¯å¦å­˜åœ¨
    sample_ids = df['id'].head(100).tolist()
    missing_count = 0
    
    for product_id in sample_ids:
        img_path = IMAGES_DIR / f"{product_id}.jpg"
        if not img_path.exists():
            missing_count += 1
    
    print(f"âœ… å‰ 100 å€‹å•†å“ä¸­ï¼Œ{100 - missing_count} å€‹æœ‰å°æ‡‰åœ–ç‰‡")
    print(f"âš ï¸  å‰ 100 å€‹å•†å“ä¸­ï¼Œ{missing_count} å€‹ç¼ºå°‘åœ–ç‰‡")
    
    if missing_count > 0:
        print(f"\nğŸ’¡ å»ºè­°: éƒ¨åˆ†å•†å“å¯èƒ½æ²’æœ‰å°æ‡‰çš„åœ–ç‰‡æª”æ¡ˆ")

def generate_summary():
    """ç”Ÿæˆæ‘˜è¦å ±å‘Š"""
    print("\n" + "=" * 80)
    print("ğŸ“ åˆ†ææ‘˜è¦")
    print("=" * 80)
    
    print(f"""
âœ… CSV æª”æ¡ˆä½ç½®: {CSV_FILE}
âœ… JSON æª”æ¡ˆç›®éŒ„: {JSON_DIR}
âœ… åœ–ç‰‡æª”æ¡ˆç›®éŒ„: {IMAGES_DIR}

ä¸‹ä¸€æ­¥å»ºè­°:
1. æ ¹æ“šåˆ†æçµæœè¨­è¨ˆè³‡æ–™åº«çµæ§‹ (Task 1.4)
2. å»ºç«‹ DBML æª”æ¡ˆå®šç¾©è³‡æ–™è¡¨
3. è™•ç†ç¼ºå¤±å€¼ç­–ç•¥
4. è¨­è¨ˆè³‡æ–™æ¸…æ´—æµç¨‹
    """)

def main():
    """ä¸»ç¨‹å¼"""
    print("\nğŸš€ Fashion Dataset è³‡æ–™åˆ†æå·¥å…·")
    print(f"ğŸ“ è³‡æ–™é›†è·¯å¾‘: {DATASET_DIR}")
    
    # æª¢æŸ¥ CSV æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not CSV_FILE.exists():
        print(f"\nâŒ æ‰¾ä¸åˆ° CSV æª”æ¡ˆ: {CSV_FILE}")
        print("è«‹ç¢ºèª fashion-dataset/styles.csv æª”æ¡ˆå­˜åœ¨")
        return
    
    # 1. åˆ†æ CSV
    df = analyze_csv()
    
    # 2. åˆ†æ JSON
    analyze_json_files(df, sample_size=10)
    
    # 3. æª¢æŸ¥åœ–ç‰‡
    check_images(df)
    
    # 4. ç”Ÿæˆæ‘˜è¦
    generate_summary()
    
    print("\nâœ… åˆ†æå®Œæˆï¼\n")

if __name__ == "__main__":
    main()
